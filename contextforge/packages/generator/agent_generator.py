"""
Agent Profile Generator â€” creates specialist agent definitions from AnalysisResult.

Generates 3 core agents for v1:
  - planner: decomposes tasks, creates implementation plans
  - reviewer: code review, convention enforcement
  - security-auditor: security scanning, vulnerability assessment
"""
from __future__ import annotations

import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

from contextforge.packages.analyzer.analyzer import AnalysisResult
from contextforge.packages.events import emit_event, CorrelationIDs

VERSION = "0.1.0"


def _provenance(result: AnalysisResult) -> dict:
    return {
        "generator": "contextforge",
        "generator_version": VERSION,
        "generated_at": datetime.now(timezone.utc).isoformat(),
        "source_commit": result.source_commit,
        "analysis_hash": result.analysis_hash,
    }


class AgentGenerator:
    """Generates specialist agent profiles from repo analysis."""

    def __init__(self, output_dir: str | Path, correlation: Optional[CorrelationIDs] = None):
        self.output_dir = Path(output_dir)
        self.correlation = correlation or CorrelationIDs()

    def generate_all(self, analysis: AnalysisResult) -> list[Path]:
        agents = []
        agents.append(self._generate_planner(analysis))
        agents.append(self._generate_reviewer(analysis))
        agents.append(self._generate_security_auditor(analysis))
        return agents

    def _write_agent(self, agent_id: str, profile: dict, prompt_md: str) -> Path:
        agent_dir = self.output_dir / agent_id
        agent_dir.mkdir(parents=True, exist_ok=True)

        with open(agent_dir / "profile.json", "w", encoding="utf-8") as f:
            json.dump(profile, f, indent=2, ensure_ascii=False)

        header = (
            f"<!-- Generated by ContextForge v{profile['provenance']['generator_version']} -->\n"
            f"<!-- Commit: {profile['provenance']['source_commit']} -->\n"
            f"<!-- Analysis hash: {profile['provenance']['analysis_hash']} -->\n\n"
        )
        with open(agent_dir / "AGENT.md", "w", encoding="utf-8") as f:
            f.write(header + prompt_md)

        emit_event("generation.agent_created", "generator", self.correlation,
                   payload={"agent_id": agent_id, "path": str(agent_dir)})

        return agent_dir

    def _generate_planner(self, a: AnalysisResult) -> Path:
        langs = ", ".join(a.stack.languages.keys())
        frameworks = ", ".join(a.stack.frameworks) if a.stack.frameworks else "none"

        prompt_md = f"""# Planner Agent

You are a planning specialist for a {langs} project using {frameworks}.

## Role
Decompose user requests into concrete, ordered implementation steps.
Each step must be specific enough for a single-focus coding session.

## Process
1. Understand the request fully before planning.
2. Check existing code structure and conventions.
3. Identify affected files and potential conflicts.
4. Create ordered steps with clear acceptance criteria.
5. Flag any risks or ambiguities for user clarification.

## Constraints
- Never execute code; only plan.
- Never modify files; only read.
- Plans must reference specific files and line ranges.
- Estimate effort per step (small/medium/large).
- Flag security implications of proposed changes.
"""

        profile = {
            "id": "planner",
            "name": "Planner",
            "role": "planner",
            "provenance": _provenance(a),
            "description": "Decomposes tasks into concrete implementation steps with file-level specificity.",
            "system_prompt_file": "AGENT.md",
            "tools": {
                "allow": ["group:fs", "group:memory"],
                "deny": ["exec", "browser", "group:runtime", "group:automation"],
            },
            "skills": ["project-overview", "code-conventions"],
            "constraints": {
                "max_concurrent": 1,
                "timeout_seconds": 120,
                "requires_approval_for": ["write", "exec"],
            },
            "tags": ["planning", "architecture"],
        }

        return self._write_agent("planner", profile, prompt_md)

    def _generate_reviewer(self, a: AnalysisResult) -> Path:
        linters = ", ".join(a.conventions.linters) or "none configured"
        formatters = ", ".join(a.conventions.formatters) or "none configured"
        test_fws = ", ".join(a.conventions.test_frameworks) or "none configured"

        prompt_md = f"""# Code Reviewer Agent

You are a code review specialist.

## Project Conventions
- **Linters**: {linters}
- **Formatters**: {formatters}
- **Test frameworks**: {test_fws}

## Review Checklist
1. **Correctness**: Does the code do what it claims?
2. **Conventions**: Does it follow project linters/formatters?
3. **Tests**: Are changes covered by tests?
4. **Security**: Any credential leaks, injection risks, or unsafe patterns?
5. **Performance**: Any obvious N+1 queries, unbounded loops, or memory leaks?
6. **Readability**: Is the code clear to a new contributor?

## Output Format
For each issue found:
- **File**: path and line range
- **Severity**: critical / major / minor / nitpick
- **Issue**: one-line description
- **Suggestion**: concrete fix
"""

        profile = {
            "id": "reviewer",
            "name": "Code Reviewer",
            "role": "reviewer",
            "provenance": _provenance(a),
            "description": "Reviews code changes for correctness, conventions, tests, and security.",
            "system_prompt_file": "AGENT.md",
            "tools": {
                "allow": ["group:fs", "group:memory"],
                "deny": ["exec", "browser", "group:runtime", "group:automation"],
            },
            "skills": ["project-overview", "code-conventions"],
            "constraints": {
                "max_concurrent": 2,
                "timeout_seconds": 180,
                "requires_approval_for": ["write", "exec"],
            },
            "tags": ["review", "quality"],
        }

        return self._write_agent("reviewer", profile, prompt_md)

    def _generate_security_auditor(self, a: AnalysisResult) -> Path:
        env_warning = "WARNING: .env files detected in repo" if a.security.has_env_files else ""
        secrets_warning = "CRITICAL: Secrets files detected" if a.security.has_secrets_file else ""
        ports = ", ".join(str(p) for p in a.security.exposed_ports) or "none"

        prompt_md = f"""# Security Auditor Agent

You are a security specialist.

## Known Security State
{env_warning}
{secrets_warning}
- Exposed ports: {ports}
- Security-relevant files: {', '.join(a.security.security_relevant_files[:10]) or 'none'}

## Audit Scope
1. **Secrets**: Scan for hardcoded credentials, API keys, tokens in code and configs.
2. **Dependencies**: Run vulnerability scans on all package managers.
3. **Injection**: Check for SQL injection, command injection, XSS, path traversal.
4. **Configuration**: Verify secure defaults (TLS, auth, CORS, CSP).
5. **Docker**: Check base image versions, run-as-root, exposed ports.
6. **CI/CD**: Verify secrets management in pipelines.

## Rules
- NEVER store or display found secrets. Report only: "Secret found in [file]:[line] (type: [api_key|password|token])".
- Always recommend remediation steps.
- Classify findings: Critical / High / Medium / Low / Informational.
"""

        profile = {
            "id": "security-auditor",
            "name": "Security Auditor",
            "role": "security",
            "provenance": _provenance(a),
            "description": "Scans for security vulnerabilities, credential leaks, and configuration issues.",
            "system_prompt_file": "AGENT.md",
            "tools": {
                "allow": ["group:fs", "exec"],
                "deny": ["browser", "group:automation", "network"],
            },
            "skills": ["project-overview", "deploy-checker", "dependency-auditor"],
            "constraints": {
                "max_concurrent": 1,
                "timeout_seconds": 300,
                "requires_approval_for": ["write", "network"],
            },
            "tags": ["security", "audit"],
        }

        return self._write_agent("security-auditor", profile, prompt_md)
